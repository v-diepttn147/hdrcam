// @generated by tools/codegen/gen.py from DispatchKeyFunctions.h

// NB: The implementing C++ file is RegisterDispatchKey.cpp

// TODO: tighten this include
#include <ATen/Functions.h>

namespace at {
namespace defaultbackend {

TORCH_API Tensor _fw_primal(const Tensor & self, int64_t level);
TORCH_API Tensor abs(const Tensor & self);
TORCH_API Tensor & abs_(Tensor & self);
TORCH_API Tensor angle(const Tensor & self);
TORCH_API Tensor sgn(const Tensor & self);
TORCH_API Tensor & sgn_(Tensor & self);
TORCH_API Tensor _conj(const Tensor & self);
TORCH_API Tensor acos(const Tensor & self);
TORCH_API Tensor & acos_(Tensor & self);
TORCH_API Tensor add(const Tensor & self, const Tensor & other, const Scalar & alpha=1);
TORCH_API Tensor & add_(Tensor & self, const Tensor & other, const Scalar & alpha=1);
TORCH_API Tensor add(const Tensor & self, const Scalar & other, const Scalar & alpha=1);
TORCH_API Tensor & add_(Tensor & self, const Scalar & other, const Scalar & alpha=1);
TORCH_API Tensor & addr_(Tensor & self, const Tensor & vec1, const Tensor & vec2, const Scalar & beta=1, const Scalar & alpha=1);
TORCH_API Tensor affine_grid_generator(const Tensor & theta, IntArrayRef size, bool align_corners);
TORCH_API Tensor acosh(const Tensor & self);
TORCH_API Tensor & acosh_(Tensor & self);
TORCH_API Tensor asinh(const Tensor & self);
TORCH_API Tensor & asinh_(Tensor & self);
TORCH_API Tensor atanh(const Tensor & self);
TORCH_API Tensor & atanh_(Tensor & self);
TORCH_API Tensor & as_strided_(Tensor & self, IntArrayRef size, IntArrayRef stride, c10::optional<int64_t> storage_offset=c10::nullopt);
TORCH_API Tensor atan(const Tensor & self);
TORCH_API Tensor & atan_(Tensor & self);
TORCH_API Tensor bernoulli(const Tensor & self, c10::optional<Generator> generator=c10::nullopt);
TORCH_API Tensor binary_cross_entropy_with_logits(const Tensor & self, const Tensor & target, const c10::optional<Tensor> & weight={}, const c10::optional<Tensor> & pos_weight={}, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor cat(TensorList tensors, int64_t dim=0);
TORCH_API Tensor & cat_out(Tensor & out, TensorList tensors, int64_t dim=0);
TORCH_API Tensor & cat_outf(TensorList tensors, int64_t dim, Tensor & out);
TORCH_API Tensor ceil(const Tensor & self);
TORCH_API Tensor & ceil_(Tensor & self);
TORCH_API Tensor & clamp_(Tensor & self, const c10::optional<Scalar> & min=c10::nullopt, const c10::optional<Scalar> & max=c10::nullopt);
TORCH_API Tensor clamp_max(const Tensor & self, const Scalar & max);
TORCH_API Tensor & clamp_max_(Tensor & self, const Scalar & max);
TORCH_API Tensor clamp_min(const Tensor & self, const Scalar & min);
TORCH_API Tensor & clamp_min_(Tensor & self, const Scalar & min);
TORCH_API Tensor complex(const Tensor & real, const Tensor & imag);
TORCH_API Tensor polar(const Tensor & abs, const Tensor & angle);
TORCH_API Tensor constant_pad_nd(const Tensor & self, IntArrayRef pad, const Scalar & value=0);
TORCH_API Tensor convolution_overrideable(const Tensor & input, const Tensor & weight, const c10::optional<Tensor> & bias, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool transposed, IntArrayRef output_padding, int64_t groups);
TORCH_API std::tuple<Tensor,Tensor,Tensor> convolution_backward_overrideable(const Tensor & grad_output, const Tensor & input, const Tensor & weight, IntArrayRef stride, IntArrayRef padding, IntArrayRef dilation, bool transposed, IntArrayRef output_padding, int64_t groups, std::array<bool,3> output_mask);
TORCH_API Tensor conv_tbc(const Tensor & self, const Tensor & weight, const Tensor & bias, int64_t pad=0);
TORCH_API Tensor & copy_(Tensor & self, const Tensor & src, bool non_blocking=false);
TORCH_API Tensor cos(const Tensor & self);
TORCH_API Tensor & cos_(Tensor & self);
TORCH_API Tensor cosh(const Tensor & self);
TORCH_API Tensor & cosh_(Tensor & self);
TORCH_API Tensor count_nonzero(const Tensor & self, c10::optional<int64_t> dim=c10::nullopt);
TORCH_API std::tuple<Tensor,Tensor> cummax(const Tensor & self, int64_t dim);
TORCH_API std::tuple<Tensor &,Tensor &> cummax_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim);
TORCH_API std::tuple<Tensor &,Tensor &> cummax_outf(const Tensor & self, int64_t dim, Tensor & values, Tensor & indices);
TORCH_API std::tuple<Tensor,Tensor> cummin(const Tensor & self, int64_t dim);
TORCH_API std::tuple<Tensor &,Tensor &> cummin_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim);
TORCH_API std::tuple<Tensor &,Tensor &> cummin_outf(const Tensor & self, int64_t dim, Tensor & values, Tensor & indices);
TORCH_API Tensor cumprod(const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumprod_(Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumprod_out(Tensor & out, const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumprod_outf(const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype, Tensor & out);
TORCH_API Tensor cumsum(const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumsum_(Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumsum_out(Tensor & out, const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype=c10::nullopt);
TORCH_API Tensor & cumsum_outf(const Tensor & self, int64_t dim, c10::optional<ScalarType> dtype, Tensor & out);
TORCH_API Tensor diagonal(const Tensor & self, int64_t offset=0, int64_t dim1=0, int64_t dim2=1);
TORCH_API Tensor div(const Tensor & self, const Scalar & other);
TORCH_API Tensor & div_(Tensor & self, const Scalar & other);
TORCH_API Tensor div(const Tensor & self, const Scalar & other, std::string rounding_mode);
TORCH_API Tensor & div_(Tensor & self, const Scalar & other, std::string rounding_mode);
TORCH_API Tensor & dot_out(Tensor & out, const Tensor & self, const Tensor & tensor);
TORCH_API Tensor & dot_outf(const Tensor & self, const Tensor & tensor, Tensor & out);
TORCH_API Tensor & vdot_out(Tensor & out, const Tensor & self, const Tensor & other);
TORCH_API Tensor & vdot_outf(const Tensor & self, const Tensor & other, Tensor & out);
TORCH_API Tensor embedding(const Tensor & weight, const Tensor & indices, int64_t padding_idx=-1, bool scale_grad_by_freq=false, bool sparse=false);
TORCH_API Tensor erf(const Tensor & self);
TORCH_API Tensor & erf_(Tensor & self);
TORCH_API Tensor erfc(const Tensor & self);
TORCH_API Tensor & erfc_(Tensor & self);
TORCH_API Tensor exp(const Tensor & self);
TORCH_API Tensor & exp_(Tensor & self);
TORCH_API Tensor exp2(const Tensor & self);
TORCH_API Tensor & exp2_(Tensor & self);
TORCH_API Tensor expm1(const Tensor & self);
TORCH_API Tensor & expm1_(Tensor & self);
TORCH_API Tensor expand(const Tensor & self, IntArrayRef size, bool implicit=false);
TORCH_API Tensor floor(const Tensor & self);
TORCH_API Tensor & floor_(Tensor & self);
TORCH_API Tensor frac(const Tensor & self);
TORCH_API Tensor & frac_(Tensor & self);
TORCH_API Tensor _grid_sampler_2d_cpu_fallback(const Tensor & input, const Tensor & grid, int64_t interpolation_mode, int64_t padding_mode, bool align_corners);
TORCH_API Tensor & index_copy_(Tensor & self, int64_t dim, const Tensor & index, const Tensor & source);
TORCH_API Tensor & index_put_(Tensor & self, const c10::List<c10::optional<Tensor>> & indices, const Tensor & values, bool accumulate=false);
TORCH_API Tensor inverse(const Tensor & self);
TORCH_API Tensor & inverse_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & inverse_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor kl_div(const Tensor & self, const Tensor & target, int64_t reduction=at::Reduction::Mean, bool log_target=false);
TORCH_API std::tuple<Tensor,Tensor> kthvalue(const Tensor & self, int64_t k, int64_t dim=-1, bool keepdim=false);
TORCH_API Tensor nan_to_num(const Tensor & self, c10::optional<double> nan=c10::nullopt, c10::optional<double> posinf=c10::nullopt, c10::optional<double> neginf=c10::nullopt);
TORCH_API Tensor & nan_to_num_(Tensor & self, c10::optional<double> nan=c10::nullopt, c10::optional<double> posinf=c10::nullopt, c10::optional<double> neginf=c10::nullopt);
TORCH_API Tensor & nan_to_num_out(Tensor & out, const Tensor & self, c10::optional<double> nan=c10::nullopt, c10::optional<double> posinf=c10::nullopt, c10::optional<double> neginf=c10::nullopt);
TORCH_API Tensor & nan_to_num_outf(const Tensor & self, c10::optional<double> nan, c10::optional<double> posinf, c10::optional<double> neginf, Tensor & out);
TORCH_API Tensor log(const Tensor & self);
TORCH_API Tensor & log_(Tensor & self);
TORCH_API Tensor log10(const Tensor & self);
TORCH_API Tensor & log10_(Tensor & self);
TORCH_API Tensor log2(const Tensor & self);
TORCH_API Tensor & log2_(Tensor & self);
TORCH_API Tensor logaddexp(const Tensor & self, const Tensor & other);
TORCH_API Tensor logaddexp2(const Tensor & self, const Tensor & other);
TORCH_API Tensor logdet(const Tensor & self);
TORCH_API Tensor logcumsumexp(const Tensor & self, int64_t dim);
TORCH_API Tensor & logcumsumexp_out(Tensor & out, const Tensor & self, int64_t dim);
TORCH_API Tensor & logcumsumexp_outf(const Tensor & self, int64_t dim, Tensor & out);
TORCH_API Tensor logsumexp(const Tensor & self, IntArrayRef dim, bool keepdim=false);
TORCH_API Tensor & logsumexp_out(Tensor & out, const Tensor & self, IntArrayRef dim, bool keepdim=false);
TORCH_API Tensor & logsumexp_outf(const Tensor & self, IntArrayRef dim, bool keepdim, Tensor & out);
TORCH_API std::tuple<Tensor,Tensor> max(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor amax(const Tensor & self, IntArrayRef dim={}, bool keepdim=false);
TORCH_API std::tuple<Tensor,Tensor> median(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API std::tuple<Tensor,Tensor> nanmedian(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API std::tuple<Tensor,Tensor> min(const Tensor & self, int64_t dim, bool keepdim=false);
TORCH_API Tensor amin(const Tensor & self, IntArrayRef dim={}, bool keepdim=false);
TORCH_API Tensor mkldnn_convolution(const Tensor & self, const Tensor & weight, const c10::optional<Tensor> & bias, IntArrayRef padding, IntArrayRef stride, IntArrayRef dilation, int64_t groups);
TORCH_API std::tuple<Tensor,Tensor,Tensor> mkldnn_convolution_backward(const Tensor & self, const Tensor & grad_output, const Tensor & weight, IntArrayRef padding, IntArrayRef stride, IntArrayRef dilation, int64_t groups, std::array<bool,3> output_mask);
TORCH_API std::tuple<Tensor &,Tensor &> mode_out(Tensor & values, Tensor & indices, const Tensor & self, int64_t dim=-1, bool keepdim=false);
TORCH_API std::tuple<Tensor &,Tensor &> mode_outf(const Tensor & self, int64_t dim, bool keepdim, Tensor & values, Tensor & indices);
TORCH_API Tensor mul(const Tensor & self, const Scalar & other);
TORCH_API Tensor & mul_(Tensor & self, const Scalar & other);
TORCH_API Tensor & mv_out(Tensor & out, const Tensor & self, const Tensor & vec);
TORCH_API Tensor & mv_outf(const Tensor & self, const Tensor & vec, Tensor & out);
TORCH_API Tensor mvlgamma(const Tensor & self, int64_t p);
TORCH_API Tensor & mvlgamma_(Tensor & self, int64_t p);
TORCH_API Tensor narrow_copy(const Tensor & self, int64_t dim, int64_t start, int64_t length);
TORCH_API Tensor _nnpack_spatial_convolution(const Tensor & input, const Tensor & weight, const c10::optional<Tensor> & bias, IntArrayRef padding, IntArrayRef stride=1);
TORCH_API Tensor _euclidean_dist(const Tensor & x1, const Tensor & x2);
TORCH_API Tensor permute(const Tensor & self, IntArrayRef dims);
TORCH_API Tensor rad2deg(const Tensor & self);
TORCH_API Tensor & rad2deg_(Tensor & self);
TORCH_API Tensor & rad2deg_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & rad2deg_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor deg2rad(const Tensor & self);
TORCH_API Tensor & deg2rad_(Tensor & self);
TORCH_API Tensor & deg2rad_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & deg2rad_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor reciprocal(const Tensor & self);
TORCH_API Tensor & reciprocal_(Tensor & self);
TORCH_API Tensor neg(const Tensor & self);
TORCH_API Tensor repeat(const Tensor & self, IntArrayRef repeats);
TORCH_API Tensor round(const Tensor & self);
TORCH_API Tensor & round_(Tensor & self);
TORCH_API Tensor rsqrt(const Tensor & self);
TORCH_API Tensor & rsqrt_(Tensor & self);
TORCH_API Tensor select(const Tensor & self, int64_t dim, int64_t index);
TORCH_API Tensor celu(const Tensor & self, const Scalar & alpha=1.0);
TORCH_API Tensor & celu_(Tensor & self, const Scalar & alpha=1.0);
TORCH_API Tensor silu(const Tensor & self);
TORCH_API Tensor & silu_(Tensor & self);
TORCH_API Tensor sin(const Tensor & self);
TORCH_API Tensor & sin_(Tensor & self);
TORCH_API Tensor sinc(const Tensor & self);
TORCH_API Tensor & sinc_(Tensor & self);
TORCH_API Tensor sinh(const Tensor & self);
TORCH_API Tensor & sinh_(Tensor & self);
TORCH_API Tensor detach(const Tensor & self);
TORCH_API Tensor & detach_(Tensor & self);
TORCH_API Tensor slice(const Tensor & self, int64_t dim=0, c10::optional<int64_t> start=0, c10::optional<int64_t> end=9223372036854775807, int64_t step=1);
TORCH_API std::tuple<Tensor,Tensor> slogdet(const Tensor & self);
TORCH_API std::vector<Tensor> unsafe_split(const Tensor & self, int64_t split_size, int64_t dim=0);
TORCH_API std::vector<Tensor> split(const Tensor & self, int64_t split_size, int64_t dim=0);
TORCH_API std::vector<Tensor> unsafe_split_with_sizes(const Tensor & self, IntArrayRef split_sizes, int64_t dim=0);
TORCH_API std::vector<Tensor> split_with_sizes(const Tensor & self, IntArrayRef split_sizes, int64_t dim=0);
TORCH_API Tensor squeeze(const Tensor & self);
TORCH_API Tensor & squeeze_(Tensor & self);
TORCH_API Tensor squeeze(const Tensor & self, int64_t dim);
TORCH_API Tensor & squeeze_(Tensor & self, int64_t dim);
TORCH_API Tensor stack(TensorList tensors, int64_t dim=0);
TORCH_API Tensor & stack_out(Tensor & out, TensorList tensors, int64_t dim=0);
TORCH_API Tensor & stack_outf(TensorList tensors, int64_t dim, Tensor & out);
TORCH_API Tensor _stack(TensorList tensors, int64_t dim=0);
TORCH_API Tensor & _stack_out(Tensor & out, TensorList tensors, int64_t dim=0);
TORCH_API Tensor & _stack_outf(TensorList tensors, int64_t dim, Tensor & out);
TORCH_API Tensor t(const Tensor & self);
TORCH_API Tensor & t_(Tensor & self);
TORCH_API Tensor tan(const Tensor & self);
TORCH_API Tensor & tan_(Tensor & self);
TORCH_API Tensor & tanh_(Tensor & self);
TORCH_API Tensor transpose(const Tensor & self, int64_t dim0, int64_t dim1);
TORCH_API Tensor & transpose_(Tensor & self, int64_t dim0, int64_t dim1);
TORCH_API Tensor rot90(const Tensor & self, int64_t k=1, IntArrayRef dims={0,1});
TORCH_API Tensor _trilinear(const Tensor & i1, const Tensor & i2, const Tensor & i3, IntArrayRef expand1, IntArrayRef expand2, IntArrayRef expand3, IntArrayRef sumdim, int64_t unroll_dim=1);
TORCH_API Tensor trunc(const Tensor & self);
TORCH_API Tensor & trunc_(Tensor & self);
TORCH_API Tensor _unsafe_view(const Tensor & self, IntArrayRef size);
TORCH_API Tensor unsqueeze(const Tensor & self, int64_t dim);
TORCH_API Tensor & unsqueeze_(Tensor & self, int64_t dim);
TORCH_API Tensor _sparse_sum(const Tensor & self, IntArrayRef dim);
TORCH_API Tensor norm(const Tensor & self, const c10::optional<Scalar> & p, ScalarType dtype);
TORCH_API Tensor norm(const Tensor & self, const Scalar & p=2);
TORCH_API Tensor norm(const Tensor & self, const c10::optional<Scalar> & p, IntArrayRef dim, bool keepdim, ScalarType dtype);
TORCH_API Tensor norm(const Tensor & self, const c10::optional<Scalar> & p, IntArrayRef dim, bool keepdim=false);
TORCH_API std::tuple<Tensor,Tensor> frexp(const Tensor & self);
TORCH_API std::tuple<Tensor &,Tensor &> frexp_out(Tensor & mantissa, Tensor & exponent, const Tensor & self);
TORCH_API std::tuple<Tensor &,Tensor &> frexp_outf(const Tensor & self, Tensor & mantissa, Tensor & exponent);
TORCH_API Tensor & resize_as_(Tensor & self, const Tensor & the_template, c10::optional<MemoryFormat> memory_format=c10::nullopt);
TORCH_API Tensor sub(const Tensor & self, const Scalar & other, const Scalar & alpha=1);
TORCH_API Tensor & sub_(Tensor & self, const Scalar & other, const Scalar & alpha=1);
TORCH_API Tensor rsub(const Tensor & self, const Scalar & other, const Scalar & alpha=1);
TORCH_API Tensor _sparse_addmm(const Tensor & self, const Tensor & sparse, const Tensor & dense, const Scalar & beta=1, const Scalar & alpha=1);
TORCH_API std::vector<Tensor> unbind(const Tensor & self, int64_t dim=0);
TORCH_API std::tuple<Tensor,Tensor> _pack_padded_sequence(const Tensor & input, const Tensor & lengths, bool batch_first);
TORCH_API Tensor view(const Tensor & self, ScalarType dtype);
TORCH_API Tensor & eq_(Tensor & self, const Scalar & other);
TORCH_API Tensor & eq_(Tensor & self, const Tensor & other);
TORCH_API Tensor tril(const Tensor & self, int64_t diagonal=0);
TORCH_API Tensor triu(const Tensor & self, int64_t diagonal=0);
TORCH_API Tensor & addcdiv_(Tensor & self, const Tensor & tensor1, const Tensor & tensor2, const Scalar & value=1);
TORCH_API Tensor addcdiv(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, const Scalar & value=1);
TORCH_API Tensor diag(const Tensor & self, int64_t diagonal=0);
TORCH_API Tensor & ne_(Tensor & self, const Scalar & other);
TORCH_API Tensor & ne_(Tensor & self, const Tensor & other);
TORCH_API Tensor & ge_(Tensor & self, const Scalar & other);
TORCH_API Tensor & ge_(Tensor & self, const Tensor & other);
TORCH_API Tensor & le_(Tensor & self, const Scalar & other);
TORCH_API Tensor & le_(Tensor & self, const Tensor & other);
TORCH_API Tensor & gt_(Tensor & self, const Scalar & other);
TORCH_API Tensor & gt_(Tensor & self, const Tensor & other);
TORCH_API Tensor & lt_(Tensor & self, const Scalar & other);
TORCH_API Tensor & lt_(Tensor & self, const Tensor & other);
TORCH_API Tensor addcmul(const Tensor & self, const Tensor & tensor1, const Tensor & tensor2, const Scalar & value=1);
TORCH_API Tensor & addcmul_(Tensor & self, const Tensor & tensor1, const Tensor & tensor2, const Scalar & value=1);
TORCH_API std::tuple<Tensor &,Tensor &> symeig_out(Tensor & e, Tensor & V, const Tensor & self, bool eigenvectors=false, bool upper=true);
TORCH_API std::tuple<Tensor &,Tensor &> symeig_outf(const Tensor & self, bool eigenvectors, bool upper, Tensor & e, Tensor & V);
TORCH_API std::tuple<Tensor,Tensor> symeig(const Tensor & self, bool eigenvectors=false, bool upper=true);
TORCH_API std::tuple<Tensor &,Tensor &> eig_out(Tensor & e, Tensor & v, const Tensor & self, bool eigenvectors=false);
TORCH_API std::tuple<Tensor &,Tensor &> eig_outf(const Tensor & self, bool eigenvectors, Tensor & e, Tensor & v);
TORCH_API std::tuple<Tensor,Tensor> eig(const Tensor & self, bool eigenvectors=false);
TORCH_API Tensor & cholesky_out(Tensor & out, const Tensor & self, bool upper=false);
TORCH_API Tensor & cholesky_outf(const Tensor & self, bool upper, Tensor & out);
TORCH_API Tensor cholesky(const Tensor & self, bool upper=false);
TORCH_API Tensor & cholesky_solve_out(Tensor & out, const Tensor & self, const Tensor & input2, bool upper=false);
TORCH_API Tensor & cholesky_solve_outf(const Tensor & self, const Tensor & input2, bool upper, Tensor & out);
TORCH_API Tensor cholesky_solve(const Tensor & self, const Tensor & input2, bool upper=false);
TORCH_API std::tuple<Tensor,Tensor> solve(const Tensor & self, const Tensor & A);
TORCH_API std::tuple<Tensor &,Tensor &> solve_out(Tensor & solution, Tensor & lu, const Tensor & self, const Tensor & A);
TORCH_API std::tuple<Tensor &,Tensor &> solve_outf(const Tensor & self, const Tensor & A, Tensor & solution, Tensor & lu);
TORCH_API Tensor & lu_solve_out(Tensor & out, const Tensor & self, const Tensor & LU_data, const Tensor & LU_pivots);
TORCH_API Tensor & lu_solve_outf(const Tensor & self, const Tensor & LU_data, const Tensor & LU_pivots, Tensor & out);
TORCH_API Tensor lu_solve(const Tensor & self, const Tensor & LU_data, const Tensor & LU_pivots);
TORCH_API Tensor polygamma(int64_t n, const Tensor & self);
TORCH_API Tensor i0(const Tensor & self);
TORCH_API Tensor & i0_(Tensor & self);
TORCH_API Tensor sign(const Tensor & self);
TORCH_API Tensor & sign_(Tensor & self);
TORCH_API Tensor dist(const Tensor & self, const Tensor & other, const Scalar & p=2);
TORCH_API Tensor & hypot_(Tensor & self, const Tensor & other);
TORCH_API Tensor & nextafter_(Tensor & self, const Tensor & other);
TORCH_API Tensor alias(const Tensor & self);
TORCH_API Tensor & l1_loss_out(Tensor & out, const Tensor & self, const Tensor & target, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor & l1_loss_outf(const Tensor & self, const Tensor & target, int64_t reduction, Tensor & out);
TORCH_API Tensor l1_loss(const Tensor & self, const Tensor & target, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor l1_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction);
TORCH_API Tensor smooth_l1_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction, double beta);
TORCH_API Tensor huber_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction, double delta);
TORCH_API Tensor & soft_margin_loss_out(Tensor & out, const Tensor & self, const Tensor & target, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor & soft_margin_loss_outf(const Tensor & self, const Tensor & target, int64_t reduction, Tensor & out);
TORCH_API Tensor soft_margin_loss(const Tensor & self, const Tensor & target, int64_t reduction=at::Reduction::Mean);
TORCH_API Tensor & soft_margin_loss_backward_out(Tensor & grad_input, const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction);
TORCH_API Tensor & soft_margin_loss_backward_outf(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction, Tensor & grad_input);
TORCH_API Tensor soft_margin_loss_backward(const Tensor & grad_output, const Tensor & self, const Tensor & target, int64_t reduction);
TORCH_API Tensor & elu_(Tensor & self, const Scalar & alpha=1, const Scalar & scale=1, const Scalar & input_scale=1);
TORCH_API Tensor rrelu_with_noise_backward(const Tensor & grad_output, const Tensor & self, const Tensor & noise, const Scalar & lower, const Scalar & upper, bool training, bool self_is_result);
TORCH_API Tensor upsample_linear1d(const Tensor & input, c10::optional<IntArrayRef> output_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_linear1d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_bilinear2d(const Tensor & input, c10::optional<IntArrayRef> output_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_bilinear2d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_trilinear3d(const Tensor & input, c10::optional<IntArrayRef> output_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_trilinear3d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_bicubic2d(const Tensor & input, c10::optional<IntArrayRef> output_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_bicubic2d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, bool align_corners, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_nearest1d(const Tensor & input, c10::optional<IntArrayRef> output_size, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_nearest1d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_nearest2d(const Tensor & input, c10::optional<IntArrayRef> output_size, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_nearest2d_backward(const Tensor & grad_output, c10::optional<IntArrayRef> output_size, IntArrayRef input_size, c10::optional<ArrayRef<double>> scale_factors);
TORCH_API Tensor upsample_linear1d(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales=c10::nullopt);
TORCH_API Tensor upsample_linear1d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales=c10::nullopt);
TORCH_API Tensor upsample_bilinear2d(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_bilinear2d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_bicubic2d(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_bicubic2d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_trilinear3d(const Tensor & self, IntArrayRef output_size, bool align_corners, c10::optional<double> scales_d=c10::nullopt, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_trilinear3d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, bool align_corners, c10::optional<double> scales_d=c10::nullopt, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_nearest1d(const Tensor & self, IntArrayRef output_size, c10::optional<double> scales=c10::nullopt);
TORCH_API Tensor upsample_nearest1d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales=c10::nullopt);
TORCH_API Tensor upsample_nearest2d(const Tensor & self, IntArrayRef output_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_nearest2d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_nearest3d(const Tensor & self, IntArrayRef output_size, c10::optional<double> scales_d=c10::nullopt, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor upsample_nearest3d_backward(const Tensor & grad_output, IntArrayRef output_size, IntArrayRef input_size, c10::optional<double> scales_d=c10::nullopt, c10::optional<double> scales_h=c10::nullopt, c10::optional<double> scales_w=c10::nullopt);
TORCH_API Tensor linalg_cholesky(const Tensor & self);
TORCH_API Tensor & linalg_cholesky_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & linalg_cholesky_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor det(const Tensor & self);
TORCH_API std::tuple<Tensor,Tensor,Tensor,Tensor> linalg_lstsq(const Tensor & self, const Tensor & b, c10::optional<double> cond=c10::nullopt, c10::optional<std::string> driver=c10::nullopt);
TORCH_API std::tuple<Tensor,Tensor> linalg_eigh(const Tensor & self, std::string UPLO="L");
TORCH_API std::tuple<Tensor &,Tensor &> linalg_eigh_out(Tensor & eigvals, Tensor & eigvecs, const Tensor & self, std::string UPLO="L");
TORCH_API std::tuple<Tensor &,Tensor &> linalg_eigh_outf(const Tensor & self, std::string UPLO, Tensor & eigvals, Tensor & eigvecs);
TORCH_API Tensor linalg_eigvalsh(const Tensor & self, std::string UPLO="L");
TORCH_API Tensor & linalg_eigvalsh_out(Tensor & out, const Tensor & self, std::string UPLO="L");
TORCH_API Tensor & linalg_eigvalsh_outf(const Tensor & self, std::string UPLO, Tensor & out);
TORCH_API Tensor linalg_inv(const Tensor & self);
TORCH_API Tensor & linalg_inv_out(Tensor & out, const Tensor & self);
TORCH_API Tensor & linalg_inv_outf(const Tensor & self, Tensor & out);
TORCH_API Tensor ger(const Tensor & self, const Tensor & vec2);
TORCH_API Tensor & ger_out(Tensor & out, const Tensor & self, const Tensor & vec2);
TORCH_API Tensor & ger_outf(const Tensor & self, const Tensor & vec2, Tensor & out);
TORCH_API Tensor linalg_solve(const Tensor & input, const Tensor & other);
TORCH_API Tensor & linalg_solve_out(Tensor & out, const Tensor & input, const Tensor & other);
TORCH_API Tensor & linalg_solve_outf(const Tensor & input, const Tensor & other, Tensor & out);
TORCH_API std::tuple<Tensor,Tensor> linalg_qr(const Tensor & self, std::string mode="reduced");
TORCH_API std::tuple<Tensor &,Tensor &> linalg_qr_out(Tensor & Q, Tensor & R, const Tensor & self, std::string mode="reduced");
TORCH_API std::tuple<Tensor &,Tensor &> linalg_qr_outf(const Tensor & self, std::string mode, Tensor & Q, Tensor & R);

} // namespace defaultbackend
} // namespace at
